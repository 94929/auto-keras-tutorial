{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTO KERAS TUTORIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from autokeras.classifier import ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# add channel value and make it 3d shape\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing search.\n",
      "Initialization finished.\n",
      "Training model  0\n",
      "Saving model.\n",
      "Model ID: 0\n",
      "Loss: tensor(11.0545)\n",
      "Accuracy 92.12\n",
      "Training model  1\n",
      "Father ID:  0\n",
      "[('to_wider_model', 1, 64)]\n",
      "Saving model.\n",
      "Model ID: 1\n",
      "Loss: tensor(6.9038)\n",
      "Accuracy 95.1\n",
      "Training model  2\n",
      "Father ID:  1\n",
      "[('to_conv_deeper_model', 1, 3), ('to_conv_deeper_model', 1, 3), ('to_conv_deeper_model', 6, 3), ('to_conv_deeper_model', 11, 3), ('to_add_skip_model', 1, 19), ('to_add_skip_model', 19, 27), ('to_add_skip_model', 27, 31), ('to_wider_model', 11, 64)]\n",
      "Saving model.\n",
      "Model ID: 2\n",
      "Loss: tensor(5.7325)\n",
      "Accuracy 95.88\n",
      "...............................................\n",
      "Epoch 1: loss 114.29173278808594, accuracy 71.55\n",
      "...............................................\n",
      "Epoch 2: loss 80.04019927978516, accuracy 78.45\n",
      "...............................................\n",
      "Epoch 3: loss 64.12076568603516, accuracy 81.67\n",
      "...............................................\n",
      "Epoch 4: loss 54.82694625854492, accuracy 83.27\n",
      "...............................................\n",
      "Epoch 5: loss 48.81724166870117, accuracy 84.26\n",
      "...............................................\n",
      "Epoch 6: loss 43.3616828918457, accuracy 85.56\n",
      "...............................................\n",
      "Epoch 7: loss 39.74256896972656, accuracy 86.57\n",
      "...............................................\n",
      "Epoch 8: loss 36.872684478759766, accuracy 87.14\n",
      "...............................................\n",
      "Epoch 9: loss 34.23834991455078, accuracy 87.98\n",
      "...............................................\n",
      "Epoch 10: loss 32.46542739868164, accuracy 88.12\n",
      "...............................................\n",
      "Epoch 11: loss 30.984296798706055, accuracy 88.81\n",
      "...............................................\n",
      "Epoch 12: loss 29.36428451538086, accuracy 89.15\n",
      "...............................................\n",
      "Epoch 13: loss 27.77242660522461, accuracy 89.76\n",
      "...............................................\n",
      "Epoch 14: loss 27.038183212280273, accuracy 90.1\n",
      "...............................................\n",
      "Epoch 15: loss 25.639678955078125, accuracy 90.52\n",
      "...............................................\n",
      "Epoch 16: loss 24.498146057128906, accuracy 91.06\n",
      "...............................................\n",
      "Epoch 17: loss 24.519500732421875, accuracy 91.03\n",
      "...............................................\n",
      "Epoch 18: loss 23.60093116760254, accuracy 91.19\n",
      "...............................................\n",
      "Epoch 19: loss 22.640172958374023, accuracy 91.56\n",
      "...............................................\n",
      "Epoch 20: loss 21.308340072631836, accuracy 92.34\n",
      "...............................................\n",
      "Epoch 21: loss 21.426664352416992, accuracy 92.11\n",
      "...............................................\n",
      "Epoch 22: loss 20.536563873291016, accuracy 92.68\n",
      "...............................................\n",
      "Epoch 23: loss 19.962453842163086, accuracy 92.73\n",
      "...............................................\n",
      "Epoch 24: loss 19.8426456451416, accuracy 92.65\n",
      "...............................................\n",
      "Epoch 25: loss 18.77017593383789, accuracy 93.18\n",
      "...............................................\n",
      "Epoch 26: loss 18.661352157592773, accuracy 93.15\n",
      "...............................................\n",
      "Epoch 27: loss 17.724031448364258, accuracy 93.45\n",
      "...............................................\n",
      "Epoch 28: loss 17.915035247802734, accuracy 93.34\n",
      "...............................................\n",
      "Epoch 29: loss 17.081342697143555, accuracy 93.74\n",
      "...............................................\n",
      "Epoch 30: loss 16.354124069213867, accuracy 94.15\n",
      "...............................................\n",
      "Epoch 31: loss 16.249813079833984, accuracy 94.22\n",
      "...............................................\n",
      "Epoch 32: loss 16.011049270629883, accuracy 94.19\n",
      "...............................................\n",
      "Epoch 33: loss 15.439072608947754, accuracy 94.61\n",
      "...............................................\n",
      "Epoch 34: loss 14.512988090515137, accuracy 94.92\n",
      "...............................................\n",
      "Epoch 35: loss 14.467720985412598, accuracy 95.01\n",
      "...............................................\n",
      "Epoch 36: loss 14.11572265625, accuracy 94.99\n",
      "...............................................\n",
      "Epoch 37: loss 14.532648086547852, accuracy 94.81\n",
      "...............................................\n",
      "Epoch 38: loss 13.58439826965332, accuracy 95.23\n",
      "...............................................\n",
      "Epoch 39: loss 13.916592597961426, accuracy 95.12\n",
      "...............................................\n",
      "Epoch 40: loss 13.203105926513672, accuracy 95.45\n",
      "...............................................\n",
      "Epoch 41: loss 13.365974426269531, accuracy 95.4\n",
      "...............................................\n",
      "Epoch 42: loss 12.898777961730957, accuracy 95.65\n",
      "...............................................\n",
      "Epoch 43: loss 12.47146987915039, accuracy 95.67\n",
      "...............................................\n",
      "Epoch 44: loss 12.27695083618164, accuracy 95.73\n",
      "...............................................\n",
      "Epoch 45: loss 12.27865982055664, accuracy 95.7\n",
      "...............................................\n",
      "Epoch 46: loss 12.223564147949219, accuracy 95.67\n",
      "...............................................\n",
      "Epoch 47: loss 11.646020889282227, accuracy 95.9\n",
      "...............................................\n",
      "Epoch 48: loss 12.016730308532715, accuracy 95.78\n",
      "...............................................\n",
      "Epoch 49: loss 11.290689468383789, accuracy 96.11\n",
      "...............................................\n",
      "Epoch 50: loss 11.129844665527344, accuracy 96.06\n",
      "...............................................\n",
      "Epoch 51: loss 11.195967674255371, accuracy 96.05\n",
      "...............................................\n",
      "Epoch 52: loss 10.918328285217285, accuracy 96.05\n",
      "...............................................\n",
      "Epoch 53: loss 10.53828239440918, accuracy 96.21\n",
      "...............................................\n",
      "Epoch 54: loss 10.490890502929688, accuracy 96.15\n",
      "...............................................\n",
      "Epoch 55: loss 10.436054229736328, accuracy 96.22\n",
      "...............................................\n",
      "Epoch 56: loss 10.320501327514648, accuracy 96.38\n",
      "...............................................\n",
      "Epoch 57: loss 10.300576210021973, accuracy 96.17\n",
      "...............................................\n",
      "Epoch 58: loss 10.218546867370605, accuracy 96.3\n",
      "...............................................\n",
      "Epoch 59: loss 10.132323265075684, accuracy 96.35\n",
      "...............................................\n",
      "Epoch 60: loss 9.789960861206055, accuracy 96.37\n",
      "...............................................\n",
      "Epoch 61: loss 9.926410675048828, accuracy 96.57\n",
      "...............................................\n",
      "Epoch 62: loss 9.837693214416504, accuracy 96.45\n",
      "...............................................\n",
      "Epoch 63: loss 10.045879364013672, accuracy 96.43\n",
      "...............................................\n",
      "Epoch 64: loss 9.410143852233887, accuracy 96.41\n",
      "...............................................\n",
      "Epoch 65: loss 9.057581901550293, accuracy 96.57\n",
      "...............................................\n",
      "Epoch 66: loss 9.461548805236816, accuracy 96.55\n",
      "...............................................\n",
      "Epoch 67: loss 8.927024841308594, accuracy 96.68\n",
      "...............................................\n",
      "Epoch 68: loss 9.257396697998047, accuracy 96.47\n",
      "...............................................\n",
      "Epoch 69: loss 8.788479804992676, accuracy 96.66\n",
      "...............................................\n",
      "Epoch 70: loss 9.10887336730957, accuracy 96.54\n",
      ".........................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49a07c59c47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mFinal\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/autokeras/classifier.py\u001b[0m in \u001b[0;36mfinal_fit\u001b[0;34m(self, x_train, y_train, x_test, y_test, trainer_args, retrain)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_model_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/autokeras/search.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    321\u001b[0m                                   \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                                   \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                                   verbose).train_model(**trainer_args)\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/autokeras/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, max_iter_num, max_no_improvement_num, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/autokeras/utils.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, loader, epoch)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/autokeras/graph.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0medge_input_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                 \u001b[0mtemp_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_input_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m                 \u001b[0mnode_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repos/keras-tutorial/kerasenv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The image classifier class. It is used for image classification. \n",
    "It searches convolutional neural network architectures for the best configuration for the dataset.\n",
    "\"\"\"\n",
    "clf = ImageClassifier(verbose=True)\n",
    "\n",
    "\"\"\"\n",
    "Find the best neural architecture and train it. \n",
    "Based on the given dataset, the function will find the best neural architecture for it. \n",
    "The dataset is in numpy.ndarray format. \n",
    "So they training data should be passed through x_train, y_train.\n",
    "\"\"\"\n",
    "clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n",
    "\n",
    "\"\"\"\n",
    "Final training after found the best architecture.\n",
    "\"\"\"\n",
    "clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return the accuracy score between predict value and test_y.\n",
    "\"\"\"\n",
    "y = clf.evaluate(x_test, y_test)\n",
    "print('The accuracy score between predict value and test_y is', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
